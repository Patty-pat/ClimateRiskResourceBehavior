{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from cprs.config import BLD\n",
    "\n",
    "# Read the arrow file\n",
    "df_main = pd.read_feather(BLD / \"data\" / \"data_clean.arrow\")\n",
    "\n",
    "# Keeping specific variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_columns = df_main.columns.tolist()\n",
    "print(list_of_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(1, 6):\n",
    "    columns_to_keep = (\n",
    "        [col for col in df_main.columns if col.startswith(f\"cs2_compr{j}\")]\n",
    "        + [col for col in df_main.columns if col.startswith(f\"cs3_compr{j}\")]\n",
    "        + [col for col in df_main.columns if col.startswith(f\"cs4_compr{j}\")]\n",
    "        + [\n",
    "            \"PLAYER_NUM\",\n",
    "            \"LAB_SESSION\",\n",
    "            \"GROUPID_ALL\",\n",
    "            \"failed_attem1\",\n",
    "            \"failed_attem2\",\n",
    "            \"failed_attem3\",\n",
    "            \"participant_id_in_session\",\n",
    "            \"player_cubicle\",\n",
    "            \"groupid1\",\n",
    "            \"groupid2\",\n",
    "            \"groupid3\",\n",
    "        ]\n",
    "        + [col for col in df_main.columns if col.startswith(\"quest_\")]\n",
    "    )\n",
    "\n",
    "    df_main = df_main[columns_to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_columns = df_main.columns.tolist()\n",
    "print(list_of_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Social Optimum Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main[\"social_optimum1\"] = df_main[\"quest_optimumN\"].apply(\n",
    "    lambda x: 1 if x == 3 else 0,\n",
    ")\n",
    "df_main[\"social_optimum2\"] = df_main[\"quest_optimumA\"].apply(\n",
    "    lambda x: 1 if x == 3 else 0,\n",
    ")\n",
    "df_main[\"social_optimum3\"] = df_main[\"quest_optimumS\"].apply(\n",
    "    lambda x: 1 if x == 3 else 0,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nash and socially acceptable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main[\"nash_strategy\"] = df_main[\"quest_strategy\"].apply(lambda x: 1 if x == 5 else 0)\n",
    "df_main[\"prosocial_perception\"] = df_main[\"quest_slider_guess\"].apply(\n",
    "    lambda x: 1 if x > 26.3 else 0,\n",
    ")\n",
    "df_main[\"social_appropriate\"] = df_main[\"quest_soc_approp_pos\"].apply(\n",
    "    lambda x: 1 if x >= 2 else 0,\n",
    ")\n",
    "df_main[\"social_appropriate\"] = df_main[\"quest_soc_approp_neg\"].apply(\n",
    "    lambda x: 1 if x < 2 else 0,\n",
    ")\n",
    "df_main[\"prosocial_perception\"] = df_main[\"quest_slider_guess\"].apply(\n",
    "    lambda x: 1 if x > 26.3 else 0,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in [\n",
    "    \"quest_eai_7\",\n",
    "    \"quest_eai_8\",\n",
    "    \"quest_eai_9\",\n",
    "    \"quest_eai_10\",\n",
    "    \"quest_eai_13\",\n",
    "    \"quest_eai_14\",\n",
    "    \"quest_eai_17\",\n",
    "    \"quest_eai_18\",\n",
    "    \"quest_eai_19\",\n",
    "    \"quest_eai_20\",\n",
    "]:\n",
    "    df_main[col] = df_main[col].apply(lambda x: 8 - x)\n",
    "\n",
    "score_columns = [\n",
    "    \"quest_eai_\" + str(i) for i in range(1, 25)\n",
    "]  # Adjust if the range is different\n",
    "df_main[\"score\"] = df_main[score_columns].sum(axis=1)\n",
    "df_main[\"GEA\"] = df_main[\"score\"] / 24\n",
    "\n",
    "print(df_main[\"GEA\"].agg([\"mean\", \"median\", \"min\", \"max\", \"count\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create binary variable 'pro_env' based on 'GEA'\n",
    "df_main[\"pro_env\"] = df_main[\"GEA\"].apply(lambda x: 1 if x > 4 else 0)\n",
    "\n",
    "# Compute group average 'GEA' score\n",
    "df_main[\"GEA_gav\"] = df_main.groupby(\"GROUPID_ALL\")[\"GEA\"].transform(\"mean\")\n",
    "\n",
    "# Create binary variable 'group_pro_env' based on 'GEA_gav'\n",
    "df_main[\"group_pro_env\"] = df_main[\"GEA_gav\"].apply(lambda x: 1 if x > 4 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Risk Preferences\n",
    "df_main = df_main.rename(columns={\"quest_gps71\": \"RISK\"})\n",
    "\n",
    "# Time Preferences\n",
    "df_main = df_main.rename(columns={\"quest_gps72_a\": \"TIME\"})\n",
    "\n",
    "# Altruistic Preferences\n",
    "df_main = df_main.rename(columns={\"quest_gps72_d\": \"ALTRUISM\"})\n",
    "\n",
    "# Negative Reciprocity\n",
    "negrec_components = [\"quest_gps72_b\", \"quest_gps72_c\", \"quest_gps73_b\"]\n",
    "df_main[\"NEGREC\"] = df_main[negrec_components].mean(axis=1)\n",
    "\n",
    "# Positive Reciprocity\n",
    "df_main = df_main.rename(columns={\"quest_gps73_a\": \"POREC\"})\n",
    "\n",
    "# Trust\n",
    "df_main = df_main.rename(columns={\"quest_gps73_c\": \"TRUST\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "education_map = {\n",
    "    \"Schulabschluss\": 1,\n",
    "    \"Ausbildung\": 2,\n",
    "    \"Bachelor-Abschluss\": 3,\n",
    "    \"Master-Abschluss\": 4,\n",
    "    \"Promotion (PhD.)\": 5,\n",
    "    \"Sonstige\": 0,\n",
    "}\n",
    "\n",
    "# Create a new column 'highest_ed' with mapped values\n",
    "df_main[\"highest_ed\"] = df_main[\"quest_highest_ed\"].map(education_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main = df_main.rename(\n",
    "    columns={\n",
    "        \"quest_q30\": \"climate_shock_concer\",\n",
    "        \"quest_q32\": \"climate_shock_impact\",\n",
    "        \"quest_q33\": \"climate_shock_cause\",\n",
    "        \"quest_q59\": \"climate_shock_main_increased_risk_reason\",\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main.loc[df_main[\"quest_study_field\"] == 3, \"quest_study_field\"] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping 'quest_study_field' values to labels\n",
    "field_labels = {1: \"1: Yes Related\", 2: \"2: Not Related\"}\n",
    "df_main[\"quest_study_field_label\"] = df_main[\"quest_study_field\"].map(field_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
